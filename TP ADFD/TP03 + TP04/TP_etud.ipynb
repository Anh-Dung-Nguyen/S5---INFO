{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TP d'acquisition de connaissances</center>\n",
    "## <center>Détection et caractérisation de POI à Rennes<br> à partir des photos publiées sur Flickr</center>\n",
    "\n",
    "<center>\n",
    "Francesco Bariatti, Peggy Cellier <br>\n",
    "2020-2021 <br>\n",
    "3INFO - Département Informatique - INSA Rennes<br> <br>\n",
    "</center>\n",
    "\n",
    "POI : point d'intérêt (Point of Interest). Pour ce TP nous considérons comme points d'intérêt les zones denses de photos publiées sur Flickr.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Introduction</font>\n",
    "## Objectifs du TP\n",
    "\n",
    "L'objectif de ce TP est de trouver, à partir de données géolocalisées dans la ville de Rennes, les points d'intérêts de ses visiteurs (résidents, touristes, ...), au moyen d'une analyse spatiale non supervisée.\n",
    "Un point d'intérêt est défini comme étant le lieu de photographies d'un grand nombre d'utilisateurs distincts.\n",
    "\n",
    "À la fin des deux séances de TP vous devrez déposer votre notebook complété sur moodle.\n",
    "\n",
    "## Jeu de données\n",
    "\n",
    "Le jeu de données correspond aux photos présentes sur flickr et géolocalisées autour de Rennes an 2019.\n",
    "[Flickr](https://www.flickr.com) est une plateforme en ligne qui permet à tout utilisateur de partager publiquement des photos contenant des informations variées comme un titre, des coordonnées géographiques ou bien encore des tags descriptifs des clichés.\n",
    "L'objectif de ce TP est d'identifier des zones denses de photos publiées sur Flickr et de les considérer comme étant des zones d'intérêt (POI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python et importation des bibliothèques utilisées pour le TP\n",
    "\n",
    "Pour ce TP, Python 3 est utilisé ainsi que plusieurs bibliothèques qu'il faut charger :\n",
    "1. **pandas** : permet de manipuler et d'analyser facilement des données  \n",
    "https://pandas.pydata.org/pandas-docs/stable/\n",
    "1. **numpy** : permet de manipuler efficacement des grandes matrices  \n",
    "http://www.numpy.org\n",
    "1. **sklearn** : offre un large choix d'algorithmes de fouille de données (mais peu d'algorithme de fouille de motifs) et d'analyse de données en général  \n",
    "https://scikit-learn.org/stable/\n",
    "1. **nltk** : permet de faire du traitement automatique des langues  \n",
    "https://www.nltk.org\n",
    "1. **mlxtend** : permet d'utiliser l'algorithme apriori  \n",
    "http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/\n",
    "1. **matplotlib** : permet des affichages scientifiques sous la forme d'histogrammes, etc.  \n",
    "https://matplotlib.org\n",
    "1. **folium** : permet d'afficher des données géolocalisées sur une carte  \n",
    "https://pypi.org/project/folium/\n",
    "1. **re** (module de la bibliothèque standard python) : permet de manipuler des expressions régulières  \n",
    "https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.3 |Anaconda custom (64-bit)| (default, Oct  6 2017, 12:04:38) \\n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérification de la version de python\n",
    "import sys\n",
    "sys.version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import des modules nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.cluster\n",
    "import nltk\n",
    "import mlxtend\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/cellier/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# La ligne suivantes permet d'importer les outils nécessaires pour utiliser l'aglorithme Apriori\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "# Les lignes de code suivantes permettent d'importer une liste de stopwrds (ou mots vides)\n",
    "# pour le français afin de les éliminer\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stopwordslist = stopwords.words(\"french\")\n",
    "stopwordslist.append(\"NaN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constantes et variables utilisées dans le TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LATITUDE, LONGITUDE = 48.117266, -1.6777926 # Latitude, longitude du centre de Rennes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Etape 1 : Préparation des données</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prise en main du jeu de données\n",
    "\n",
    "Les informations concernant les photos sont stockées dans un fichier csv (`flickrRennes.csv`).\n",
    "Pour manipuler aisément ces données nous les chargeons dans un `DataFrame` (structure de données de la bibliothèque pandas) directement à partir du fichier csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "photos_orig = pd.read_csv(\"flickrRennes.csv\")\n",
    "photos = photos_orig.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du tableau chargé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_photo</th>\n",
       "      <th>title</th>\n",
       "      <th>id_photographer</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>date_uploaded</th>\n",
       "      <th>date_uploaded_year</th>\n",
       "      <th>date_uploaded_month</th>\n",
       "      <th>date_uploaded_day</th>\n",
       "      <th>date_uploaded_hour</th>\n",
       "      <th>date_uploaded_minutes</th>\n",
       "      <th>date_taken</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47146974932</td>\n",
       "      <td>Le Thabor</td>\n",
       "      <td>132905622@N08</td>\n",
       "      <td>48.114193</td>\n",
       "      <td>-1.673054</td>\n",
       "      <td>rennes bretagne eglise parc thabor</td>\n",
       "      <td>https://www.flickr.com/photos/132905622@N08/47...</td>\n",
       "      <td>2019-02-24 18:35:30</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-02-24 16:54:28</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46283874935</td>\n",
       "      <td>Ressort Rennes - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>Ressort Rennes ATANA studio Anthony SÉJOURNÉ</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4628...</td>\n",
       "      <td>2019-02-24 17:38:41</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-21 22:25:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46283874465</td>\n",
       "      <td>Action Joe - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>Action Joe ATANA studio Anthony SÉJOURNÉ</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4628...</td>\n",
       "      <td>2019-02-24 17:38:42</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-21 22:31:21</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32256187777</td>\n",
       "      <td>Ressort Rennes - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>Ressort Rennes ATANA studio Anthony SÉJOURNÉ</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/3225...</td>\n",
       "      <td>2019-02-24 17:38:43</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-22 16:48:57</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46474676184</td>\n",
       "      <td>Colors - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>Colors ATANA studio Anthony SÉJOURNÉ</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4647...</td>\n",
       "      <td>2019-02-24 17:38:43</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-22 16:50:45</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id_photo                          title id_photographer        lat  \\\n",
       "0  47146974932                      Le Thabor   132905622@N08  48.114193   \n",
       "1  46283874935  Ressort Rennes - atana studio    27111862@N06  48.099406   \n",
       "2  46283874465      Action Joe - atana studio    27111862@N06  48.099406   \n",
       "3  32256187777  Ressort Rennes - atana studio    27111862@N06  48.099406   \n",
       "4  46474676184          Colors - atana studio    27111862@N06  48.099406   \n",
       "\n",
       "       long                                          tags  \\\n",
       "0 -1.673054            rennes bretagne eglise parc thabor   \n",
       "1 -1.671262  Ressort Rennes ATANA studio Anthony SÉJOURNÉ   \n",
       "2 -1.671262      Action Joe ATANA studio Anthony SÉJOURNÉ   \n",
       "3 -1.671262  Ressort Rennes ATANA studio Anthony SÉJOURNÉ   \n",
       "4 -1.671262          Colors ATANA studio Anthony SÉJOURNÉ   \n",
       "\n",
       "                                                 url        date_uploaded  \\\n",
       "0  https://www.flickr.com/photos/132905622@N08/47...  2019-02-24 18:35:30   \n",
       "1  https://www.flickr.com/photos/atanastudio/4628...  2019-02-24 17:38:41   \n",
       "2  https://www.flickr.com/photos/atanastudio/4628...  2019-02-24 17:38:42   \n",
       "3  https://www.flickr.com/photos/atanastudio/3225...  2019-02-24 17:38:43   \n",
       "4  https://www.flickr.com/photos/atanastudio/4647...  2019-02-24 17:38:43   \n",
       "\n",
       "   date_uploaded_year  date_uploaded_month  date_uploaded_day  \\\n",
       "0                2019                    2                 24   \n",
       "1                2019                    2                 24   \n",
       "2                2019                    2                 24   \n",
       "3                2019                    2                 24   \n",
       "4                2019                    2                 24   \n",
       "\n",
       "   date_uploaded_hour  date_uploaded_minutes           date_taken  \\\n",
       "0                  18                     35  2019-02-24 16:54:28   \n",
       "1                  17                     38  2019-02-21 22:25:00   \n",
       "2                  17                     38  2019-02-21 22:31:21   \n",
       "3                  17                     38  2019-02-22 16:48:57   \n",
       "4                  17                     38  2019-02-22 16:50:45   \n",
       "\n",
       "   date_taken_year  date_taken_month  date_taken_day  date_taken_hour  \\\n",
       "0             2019                 2              24               16   \n",
       "1             2019                 2              21               22   \n",
       "2             2019                 2              21               22   \n",
       "3             2019                 2              22               16   \n",
       "4             2019                 2              22               16   \n",
       "\n",
       "   date_taken_minutes  \n",
       "0                  54  \n",
       "1                  25  \n",
       "2                  31  \n",
       "3                  48  \n",
       "4                  50  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description des colonnes :\n",
    "- **id\\_photo** = identifiant de la photo\n",
    "- **title** = titre de la photo\n",
    "- **id\\_photographer** = identifiant du propriétaire de la photo (utilisateur qui a publié la photo)\n",
    "- **lat, long** = coordonnées géographiques de la prise de vue\n",
    "- **tags** = les tags fournis par l'utilisateur\n",
    "- **url** = lien de la photo\n",
    "- **date\\_uploaded*** = champs avec informations sur la date de publication de la photo\n",
    "- **date\\_taken*** = champs avec informations sur la date de prise de la photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez le nombre de photos contenues dans le DataFrame.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez les valeurs moyennes et medianes de la latitude et longitude. Cela vous paraît-il cohérent ?*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *De quelle année date la photo la plus ancienne ? Et la plus récente ?*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez le nombre d'utilisateurs distincts.* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez le nombre de valeurs distinctes de id_photo.* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suppression des doublons\n",
    "Les identifiants des photos sont censés être uniques, pourtant la question précédente affiche un nombre d'identifiants bien inférieur au nombre de lignes du DataFrame. Il est fort possible qu'il y ait des doublons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Supprimez les lignes en double*  \n",
    "Indication: la documentation de la classe DataFrame se trouve ici: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez la nouvelle taille du jeu de données* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Afficher le nombre de photos par utilisateurs distincts.* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez le nombre d'utilisateurs n'ayant posté qu'une seule photo.* </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les questions suivantes, vous allez devoir créer des graphiques avec le module `matplotlib.pyplot`. Une liste des fonctions disponibles est présente à cette adresse : https://matplotlib.org/api/pyplot_summary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8X8P2wUspeZw7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12fb1f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example de création de graphique avec matplotlib\n",
    "x = [1, 2, 3, 4, 5]\n",
    "y = [7, 12, 3, 17, 4]\n",
    "\n",
    "plt.plot(x, y, \"+\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Combien de photos prennent les photographes de ce jeu de données ? Afficher la distribution du nombre de photographes par nombre de photos.* </font>  \n",
    "Le résultat devrait ressembler à l'image suivante:  \n",
    "![Photographes par nombre de photos](photographes_par_photo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Afficher un diagramme à barres de la distribution des photos sur les mois de l'année.* </font>  \n",
    "Indication: la fonction matplotlib à utiliser est `bar`, la fonction `hist` [n'est pas ce que vous cherchez](https://giphy.com/embed/fZyssFynWmQSc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des données sur une carte\n",
    "Le code suivant permet d'afficher la position des photos sur une carte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    }
   ],
   "source": [
    "rennes_map = folium.Map(location = [LATITUDE, LONGITUDE], tiles=\"cartodbpositron\", zoom_start = 12)\n",
    "\n",
    "for row_nb, row in photos.iterrows():\n",
    "    folium.CircleMarker([row[\"lat\"], row[\"long\"]], radius = 1).add_to(rennes_map)\n",
    "\n",
    "# Alternativement, la boucle peut être remplacée par la ligne suivante (approche fonctionnelle) :\n",
    "#photos.apply(lambda row: folium.CircleMarker([row[\"lat\"], row[\"long\"]], radius = 1).add_to(rennes_map), axis = 1)\n",
    "\n",
    "# La ligne suivante permet d'enregistrer la carte\n",
    "#rennes_map.save(\"rennes_map.html\")\n",
    "\n",
    "rennes_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitation de l'effet \"album photo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certains utilisateurs publient des séries de photos, généralemment prises au même endroit, dans un court laps de temps (quelques minutes). Par exemple : un utilisateur qui prend (et publie sur Flickr) plusieurs photos de son chat à son domicile. Il est évident que cet album photo, bien que le nombre de photos soit \"conséquent\", ne représente pas un point d'intérêt.  \n",
    "Un centre d’intérêt doit être le lieu de photographies d’un grand nombre d’utilisateurs distincts et non pas d’une personne isolée.\n",
    "\n",
    "Il est nécéssaire de traiter les données afin d'éliminer, ou du moins réduire, ce phénomène.  \n",
    "Une solution, très simpliste, est de ne garder dans notre analyse qu'une photo par utilisateur par heure de temps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Donnez l'instruction pandas correspondante et critiquez-la. Mettez ensuite à jour le DataFrame photos en gardant une seule photo par groupe.*  </font> \n",
    "Indication : utiliser la méthode `groupby` avec plusieurs groupements.  \n",
    "Note: passer le parametre `as_index = False` à la fonction pour éviter la création d'un index multiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez le DataFrame modifié*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez le nombre de photos contenues dans le DataFrame.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez les photos du DataFrame sur une carte.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Etape 2 : Clustering des photos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel sur le clustering\n",
    "\n",
    "Le clustering est une technique permettant de classer un ensemble d’objets (observations) par groupes appelés clusters ou classes. L’idée d’une méthode de clustering est généralement de maximiser la similarité des observations à l’intérieur d’un même cluster et de minimiser la similarité entre deux objets de clusters distincts.\n",
    "\n",
    "\n",
    "Il existe un grand nombre d’algorithmes de clustering, parmi lesquels se trouvent KMeans et DBSCAN que l’on comparera par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans\n",
    "Cet algorithme permet de grouper l’ensemble d’un « dataset » et donc de former des clusters. \n",
    "« Means » veut dire moyennes, l’algorithme KMeans identifie k points représentatifs, appelés moyennes, auxquels sont associés ensuite les autres points du jeu de données en fonction de leur proximité avec ces moyennes.\n",
    "\n",
    "**Avantages** : KMeans est un algorithme très rapide, de complexité linéaire par rapport aux données. Il peut donc traiter de très grandes bases. Il n’y a pas de calcul de distance entre deux observations (2 à 2) à calculer, ce qui va à son avantage.\n",
    "\n",
    "**Inconvénients** : KMeans a besoin en entrée du nombre de classes (clusters) K. Lorsque l’on souhaite analyser un dataset, nous ne connaissons pas toujours à l’avance ce nombre.\n",
    "De plus, plusieurs exécutions de l’algorithme peuvent ne pas donner le même résultat en fonction de l’initialisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "DBSCAN pour « Density-Based Spatial Clustering of Applications with Noise » est un algorithme de clustering basé \n",
    "sur la densité, dont le but est d’identifier, dans l’espace, les zones de forte densité. \n",
    "Celles-ci sont entourées de zones à faible densité que l’on appelle le bruit (d’où le « with Noise » dans le nom). \n",
    "L’intérêt est d’extraire les groupes à forte densité afin d’en découvrir des connaissances (centres d’intérêts).\n",
    "\n",
    "DBSCAN a une complexité en O(n ∗ log(n)). Il est basé sur la densité. \n",
    "Il n’a pas besoin que l’on lui indique le nombre de clusters à identifier. Les seuls arguments dont il a besoin sont :\n",
    "\n",
    "- epsilon : la distance maximale que doit avoir un point a avec un point b appartenant à un cluster pour prétendre en faire partie également.\n",
    "- minPts : le nombre de points minimum pour qu’un groupe de points puisse être identifié comme un cluster\n",
    "\n",
    "\n",
    "**Avantages** : DBSCAN permet d’éliminer le bruit de la classification et donc d’ignorer les valeurs aberrantes (outliers). Les clusters à base de densité, comme ceux produits par DBSCAN ne suivent pas un modèle de forme particulier. Il suffit d’un ensemble de points toujours liés par une distance inférieure à epsilon pour qu’il soit identifié comme un cluster (à condition que cet ensemble contient au moins minPts).  \n",
    "Par exemple, dans le cadre de notre projet, nous pouvons imaginer un cluster de photos qui longe une rivière sur plusieurs kilomètres. Nous pouvons également imaginer un cluster qui entoure entièrement un autre cluster avec cet algorithme (cf. figure ci-dessous).\n",
    "\n",
    "\n",
    "**Limite** : DBSCAN s’applique à des données « homogènes » par leur répartition et leur densité. Il ne permet de traiter qu’un type de densités à la fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans vs DBSCAN\n",
    "![kmeans vs dbscan](kmeans_vs_dbscan.png)\n",
    "\n",
    "**Clusters de forme convexe** : KMeans est une méthode qui se base sur des centroïdes. Les clusters détiennent les observations qui sont proches de leurs centres. Nous pouvons voir sur la figure ci-dessus — qui illustre le comportement de KMeans et de DBSCAN pour deux types de datasets différents — que KMeans distribue des clusters convexes autour des centres. Si l’on prend deux points quelconques d’un cluster convexe, le segment entre ces deux points appartiendra à la droite. C’est la définition d’une forme convexe (cf. définition d’un polygone convexe). Un cercle, un losange, une ellipse sont toutes des formes convexes.\n",
    "\n",
    "**Clusters de forme non convexe (concave)** : DBSCAN, peut fournir des clusters concaves. Une demie lune est une forme concave : si l’on prend deux points aux extrémités de la demie lune, le segment qui les lie sort de la forme en question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification des points d'intérêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Choisissez un algorithme pour notre problème parmi ces 2 algorithmes en justifiant votre choix.*</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Réponse :*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Appliquez l'algorithme sur les données en utilisant soit `sklearn.cluster.KMeans` ou `sklearn.cluster.DBSCAN`*</font>\n",
    "\n",
    "Vous pouvez afficher l'aide python (contenant des exemples d'utilisation) sur ces algorithmes avec la fonction`help(nom_complet_algorithme)`\n",
    "\n",
    "Paramètres conseillés:\n",
    "- Pour KMeans: \n",
    "    - `n_clusters` : à vous de le déterminer\n",
    "- Pour DBSCAN:\n",
    "    - `eps` : 0.00030\n",
    "    - `min_samples` : 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KMeans in module sklearn.cluster.k_means_:\n",
      "\n",
      "class KMeans(sklearn.base.BaseEstimator, sklearn.base.ClusterMixin, sklearn.base.TransformerMixin)\n",
      " |  K-Means clustering\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <k_means>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  n_clusters : int, optional, default: 8\n",
      " |      The number of clusters to form as well as the number of\n",
      " |      centroids to generate.\n",
      " |  \n",
      " |  init : {'k-means++', 'random' or an ndarray}\n",
      " |      Method for initialization, defaults to 'k-means++':\n",
      " |  \n",
      " |      'k-means++' : selects initial cluster centers for k-mean\n",
      " |      clustering in a smart way to speed up convergence. See section\n",
      " |      Notes in k_init for more details.\n",
      " |  \n",
      " |      'random': choose k observations (rows) at random from data for\n",
      " |      the initial centroids.\n",
      " |  \n",
      " |      If an ndarray is passed, it should be of shape (n_clusters, n_features)\n",
      " |      and gives the initial centers.\n",
      " |  \n",
      " |  n_init : int, default: 10\n",
      " |      Number of time the k-means algorithm will be run with different\n",
      " |      centroid seeds. The final results will be the best output of\n",
      " |      n_init consecutive runs in terms of inertia.\n",
      " |  \n",
      " |  max_iter : int, default: 300\n",
      " |      Maximum number of iterations of the k-means algorithm for a\n",
      " |      single run.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Relative tolerance with regards to inertia to declare convergence\n",
      " |  \n",
      " |  precompute_distances : {'auto', True, False}\n",
      " |      Precompute distances (faster but takes more memory).\n",
      " |  \n",
      " |      'auto' : do not precompute distances if n_samples * n_clusters > 12\n",
      " |      million. This corresponds to about 100MB overhead per job using\n",
      " |      double precision.\n",
      " |  \n",
      " |      True : always precompute distances\n",
      " |  \n",
      " |      False : never precompute distances\n",
      " |  \n",
      " |  verbose : int, default 0\n",
      " |      Verbosity mode.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None (default)\n",
      " |      Determines random number generation for centroid initialization. Use\n",
      " |      an int to make the randomness deterministic.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  copy_x : boolean, optional\n",
      " |      When pre-computing distances it is more numerically accurate to center\n",
      " |      the data first.  If copy_x is True (default), then the original data is\n",
      " |      not modified, ensuring X is C-contiguous.  If False, the original data\n",
      " |      is modified, and put back before the function returns, but small\n",
      " |      numerical differences may be introduced by subtracting and then adding\n",
      " |      the data mean, in this case it will also not ensure that data is\n",
      " |      C-contiguous which may cause a significant slowdown.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to use for the computation. This works by computing\n",
      " |      each of the n_init runs in parallel.\n",
      " |  \n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  algorithm : \"auto\", \"full\" or \"elkan\", default=\"auto\"\n",
      " |      K-means algorithm to use. The classical EM-style algorithm is \"full\".\n",
      " |      The \"elkan\" variation is more efficient by using the triangle\n",
      " |      inequality, but currently doesn't support sparse data. \"auto\" chooses\n",
      " |      \"elkan\" for dense data and \"full\" for sparse data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  cluster_centers_ : array, [n_clusters, n_features]\n",
      " |      Coordinates of cluster centers\n",
      " |  \n",
      " |  labels_ :\n",
      " |      Labels of each point\n",
      " |  \n",
      " |  inertia_ : float\n",
      " |      Sum of squared distances of samples to their closest cluster center.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Number of iterations run.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> from sklearn.cluster import KMeans\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [1, 4], [1, 0],\n",
      " |  ...               [4, 2], [4, 4], [4, 0]])\n",
      " |  >>> kmeans = KMeans(n_clusters=2, random_state=0).fit(X)\n",
      " |  >>> kmeans.labels_\n",
      " |  array([0, 0, 0, 1, 1, 1], dtype=int32)\n",
      " |  >>> kmeans.predict([[0, 0], [4, 4]])\n",
      " |  array([0, 1], dtype=int32)\n",
      " |  >>> kmeans.cluster_centers_\n",
      " |  array([[1., 2.],\n",
      " |         [4., 2.]])\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  \n",
      " |  MiniBatchKMeans\n",
      " |      Alternative online implementation that does incremental updates\n",
      " |      of the centers positions using mini-batches.\n",
      " |      For large scale learning (say n_samples > 10k) MiniBatchKMeans is\n",
      " |      probably much faster than the default batch implementation.\n",
      " |  \n",
      " |  Notes\n",
      " |  ------\n",
      " |  The k-means problem is solved using either Lloyd's or Elkan's algorithm.\n",
      " |  \n",
      " |  The average complexity is given by O(k n T), were n is the number of\n",
      " |  samples and T is the number of iteration.\n",
      " |  \n",
      " |  The worst case complexity is given by O(n^(k+2/p)) with\n",
      " |  n = n_samples, p = n_features. (D. Arthur and S. Vassilvitskii,\n",
      " |  'How slow is the k-means method?' SoCG2006)\n",
      " |  \n",
      " |  In practice, the k-means algorithm is very fast (one of the fastest\n",
      " |  clustering algorithms available), but it falls in local minima. That's why\n",
      " |  it can be useful to restart it several times.\n",
      " |  \n",
      " |  If the algorithm stops before fully converging (because of ``tol`` of\n",
      " |  ``max_iter``), ``labels_`` and ``means_`` will not be consistent, i.e. the\n",
      " |  ``means_`` will not be the means of the points in each cluster.\n",
      " |  Also, the estimator will reassign ``labels_`` after the last iteration to\n",
      " |  make ``labels_`` consistent with ``predict`` on the training set.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KMeans\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=None, algorithm='auto')\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Compute k-means clustering.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape=(n_samples, n_features)\n",
      " |          Training instances to cluster. It must be noted that the data\n",
      " |          will be converted to C ordering, which will cause a memory\n",
      " |          copy if the given data is not C-contiguous.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |  \n",
      " |  fit_predict(self, X, y=None, sample_weight=None)\n",
      " |      Compute cluster centers and predict cluster index for each sample.\n",
      " |      \n",
      " |      Convenience method; equivalent to calling fit(X) followed by\n",
      " |      predict(X).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape [n_samples,]\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, sample_weight=None)\n",
      " |      Compute clustering and transform X to cluster-distance space.\n",
      " |      \n",
      " |      Equivalent to fit(X).transform(X), but more efficiently implemented.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape [n_samples, k]\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  predict(self, X, sample_weight=None)\n",
      " |      Predict the closest cluster each sample in X belongs to.\n",
      " |      \n",
      " |      In the vector quantization literature, `cluster_centers_` is called\n",
      " |      the code book and each value returned by `predict` is the index of\n",
      " |      the closest code in the code book.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to predict.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      labels : array, shape [n_samples,]\n",
      " |          Index of the cluster each sample belongs to.\n",
      " |  \n",
      " |  score(self, X, y=None, sample_weight=None)\n",
      " |      Opposite of the value of X on the K-means objective.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |          not used, present here for API consistency by convention.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional\n",
      " |          The weights for each observation in X. If None, all observations\n",
      " |          are assigned equal weight (default: None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Opposite of the value of X on the K-means objective.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform X to a cluster-distance space.\n",
      " |      \n",
      " |      In the new space, each dimension is the distance to the cluster\n",
      " |      centers.  Note that even if X is sparse, the array returned by\n",
      " |      `transform` will typically be dense.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
      " |          New data to transform.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape [n_samples, k]\n",
      " |          X transformed in the new space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n",
      "Help on class DBSCAN in module sklearn.cluster.dbscan_:\n",
      "\n",
      "class DBSCAN(sklearn.base.BaseEstimator, sklearn.base.ClusterMixin)\n",
      " |  Perform DBSCAN clustering from vector array or distance matrix.\n",
      " |  \n",
      " |  DBSCAN - Density-Based Spatial Clustering of Applications with Noise.\n",
      " |  Finds core samples of high density and expands clusters from them.\n",
      " |  Good for data which contains clusters of similar density.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <dbscan>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  eps : float, optional\n",
      " |      The maximum distance between two samples for them to be considered\n",
      " |      as in the same neighborhood.\n",
      " |  \n",
      " |  min_samples : int, optional\n",
      " |      The number of samples (or total weight) in a neighborhood for a point\n",
      " |      to be considered as a core point. This includes the point itself.\n",
      " |  \n",
      " |  metric : string, or callable\n",
      " |      The metric to use when calculating distance between instances in a\n",
      " |      feature array. If metric is a string or callable, it must be one of\n",
      " |      the options allowed by :func:`sklearn.metrics.pairwise_distances` for\n",
      " |      its metric parameter.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square. X may be a sparse matrix, in which case only \"nonzero\"\n",
      " |      elements may be considered neighbors for DBSCAN.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         metric *precomputed* to accept precomputed sparse matrix.\n",
      " |  \n",
      " |  metric_params : dict, optional\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
      " |      The algorithm to be used by the NearestNeighbors module\n",
      " |      to compute pointwise distances and find nearest neighbors.\n",
      " |      See NearestNeighbors module documentation for details.\n",
      " |  \n",
      " |  leaf_size : int, optional (default = 30)\n",
      " |      Leaf size passed to BallTree or cKDTree. This can affect the speed\n",
      " |      of the construction and query, as well as the memory required\n",
      " |      to store the tree. The optimal value depends\n",
      " |      on the nature of the problem.\n",
      " |  \n",
      " |  p : float, optional\n",
      " |      The power of the Minkowski metric to be used to calculate distance\n",
      " |      between points.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of parallel jobs to run.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  core_sample_indices_ : array, shape = [n_core_samples]\n",
      " |      Indices of core samples.\n",
      " |  \n",
      " |  components_ : array, shape = [n_core_samples, n_features]\n",
      " |      Copy of each core sample found by training.\n",
      " |  \n",
      " |  labels_ : array, shape = [n_samples]\n",
      " |      Cluster labels for each point in the dataset given to fit().\n",
      " |      Noisy samples are given the label -1.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.cluster import DBSCAN\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 2], [2, 2], [2, 3],\n",
      " |  ...               [8, 7], [8, 8], [25, 80]])\n",
      " |  >>> clustering = DBSCAN(eps=3, min_samples=2).fit(X)\n",
      " |  >>> clustering.labels_\n",
      " |  array([ 0,  0,  0,  1,  1, -1])\n",
      " |  >>> clustering # doctest: +NORMALIZE_WHITESPACE\n",
      " |  DBSCAN(algorithm='auto', eps=3, leaf_size=30, metric='euclidean',\n",
      " |      metric_params=None, min_samples=2, n_jobs=None, p=None)\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  For an example, see :ref:`examples/cluster/plot_dbscan.py\n",
      " |  <sphx_glr_auto_examples_cluster_plot_dbscan.py>`.\n",
      " |  \n",
      " |  This implementation bulk-computes all neighborhood queries, which increases\n",
      " |  the memory complexity to O(n.d) where d is the average number of neighbors,\n",
      " |  while original DBSCAN had memory complexity O(n). It may attract a higher\n",
      " |  memory complexity when querying these nearest neighborhoods, depending\n",
      " |  on the ``algorithm``.\n",
      " |  \n",
      " |  One way to avoid the query complexity is to pre-compute sparse\n",
      " |  neighborhoods in chunks using\n",
      " |  :func:`NearestNeighbors.radius_neighbors_graph\n",
      " |  <sklearn.neighbors.NearestNeighbors.radius_neighbors_graph>` with\n",
      " |  ``mode='distance'``, then using ``metric='precomputed'`` here.\n",
      " |  \n",
      " |  Another way to reduce memory and computation time is to remove\n",
      " |  (near-)duplicate points and use ``sample_weight`` instead.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Ester, M., H. P. Kriegel, J. Sander, and X. Xu, \"A Density-Based\n",
      " |  Algorithm for Discovering Clusters in Large Spatial Databases with Noise\".\n",
      " |  In: Proceedings of the 2nd International Conference on Knowledge Discovery\n",
      " |  and Data Mining, Portland, OR, AAAI Press, pp. 226-231. 1996\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DBSCAN\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClusterMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, eps=0.5, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, sample_weight=None)\n",
      " |      Perform DBSCAN clustering from features or distance matrix.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array or sparse (CSR) matrix of shape (n_samples, n_features), or                 array of shape (n_samples, n_samples)\n",
      " |          A feature array, or array of distances between samples if\n",
      " |          ``metric='precomputed'``.\n",
      " |      sample_weight : array, shape (n_samples,), optional\n",
      " |          Weight of each sample, such that a sample with a weight of at least\n",
      " |          ``min_samples`` is by itself a core sample; a sample with negative\n",
      " |          weight may inhibit its eps-neighbor from being core.\n",
      " |          Note that weights are absolute, and default to 1.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |  \n",
      " |  fit_predict(self, X, y=None, sample_weight=None)\n",
      " |      Performs clustering on X and returns cluster labels.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array or sparse (CSR) matrix of shape (n_samples, n_features), or                 array of shape (n_samples, n_samples)\n",
      " |          A feature array, or array of distances between samples if\n",
      " |          ``metric='precomputed'``.\n",
      " |      sample_weight : array, shape (n_samples,), optional\n",
      " |          Weight of each sample, such that a sample with a weight of at least\n",
      " |          ``min_samples`` is by itself a core sample; a sample with negative\n",
      " |          weight may inhibit its eps-neighbor from being core.\n",
      " |          Note that weights are absolute, and default to 1.\n",
      " |      \n",
      " |      y : Ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray, shape (n_samples,)\n",
      " |          cluster labels\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn.cluster.KMeans)\n",
    "help(sklearn.cluster.DBSCAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez la liste des labels des clusters crées*</font>  \n",
    "Vous devez obtenir un tableau qui indique le numéro de cluster de chaque photo, comme celui-ci : array([-1, -1, -1, ..., -1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Ajoutez ces informations au DataFrame, dans une nouvelle colonne \"cluster\". Affichez le DataFrame.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez la liste des labels de cluster du DataFrame, sans les doublons. Quel label est utilisé pour marquer une photo qui n'appartient pas à un cluster ?*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez les url de toutes les photos appartenant au cluster de label 2.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage sur une carte\n",
    "Nous voulons maintenant afficher les clusters sur une carte.\n",
    "\n",
    "Nous vous fournissons une fonction qui permet d'associer une couleur à un label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLORS = [\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"darkred\", \"lightred\", \"darkblue\", \"darkgreen\", \"cadetblue\", \"pink\", \"lightblue\", \"lightgreen\", \"gray\", \"black\"]\n",
    "\n",
    "def get_color(label):\n",
    "    if label < 0: # Bruit\n",
    "        return \"lightgray\"\n",
    "    else:\n",
    "        return COLORS[label % len(COLORS)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Affichez les photos sur une carte, avec pour chaque photo une couleur correspondante au cluster dont elle fait partie.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons rendre les clusters plus visibles. Pour cela nous allons créer un `folium.Marker` par cluster.\n",
    "\n",
    "<font color=orange>**Question** : *Modifiez la question précédente pour ajouter un marqueur par cluster (au milieu de préférence) , de la bonne couleur et avec un texte indiquant le label du cluster.*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question(s) bonus\n",
    "S'il vous reste du temps, vous pouvez essayer de jouer sur les paramètres de clustering pour avoir des clusters qui correspondent à votre idée de point d’intérêt de Rennes, ajouter un lien vers une photo du cluster dans les popups, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue>Etape 3 : Caractérisation des clusters</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au delà des descripteurs spatiaux (latitude et longitude), les tags des photos sont fournis. Bien que renseignés par l’utilisateur, ils peuvent être source d’informations supplémentaires à propos du lieu de prise de la photo. Ils pourraient également permettre de caractériser les classes/clusters/groupes de photos, i.e. les points d’intérêt. \n",
    "<br>\n",
    "<br>\n",
    "    La solution est d’utiliser les informations de chaque photo, en particulier ses tags.\n",
    "    \n",
    "<!--La Table 4 représente les tags les plus représentatifs pour quelques clusters de notre étude. En d’autres termes elle illustre des exemples de points d’intérêt de Rennes caractérisés par les tags de leurs photos. Ceci est un extrait de ce qui devrait être obtenu à l’issue de cette partie.  \n",
    "  \n",
    "IMAGE A AJOUTER-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prétraitement et nettoyage des tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction magic nettoie les tags des photos. Afin de vous faire gagner du temps, cette fonction \"masquée\" vous est donnée.\n",
    "\n",
    "**Vous devez quand même changer le nom de la variable photos si votre dataframe ne s'appelle pas photos.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_photo</th>\n",
       "      <th>title</th>\n",
       "      <th>id_photographer</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>date_uploaded</th>\n",
       "      <th>date_uploaded_year</th>\n",
       "      <th>date_uploaded_month</th>\n",
       "      <th>date_uploaded_day</th>\n",
       "      <th>date_uploaded_hour</th>\n",
       "      <th>date_uploaded_minutes</th>\n",
       "      <th>date_taken</th>\n",
       "      <th>date_taken_year</th>\n",
       "      <th>date_taken_month</th>\n",
       "      <th>date_taken_day</th>\n",
       "      <th>date_taken_hour</th>\n",
       "      <th>date_taken_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47146974932</td>\n",
       "      <td>Le Thabor</td>\n",
       "      <td>132905622@N08</td>\n",
       "      <td>48.114193</td>\n",
       "      <td>-1.673054</td>\n",
       "      <td>rennes bretagne eglise parc thabor</td>\n",
       "      <td>https://www.flickr.com/photos/132905622@N08/47...</td>\n",
       "      <td>2019-02-24 18:35:30</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-02-24 16:54:28</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46283874935</td>\n",
       "      <td>Ressort Rennes - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>ressort rennes atana studio anthony sejourne</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4628...</td>\n",
       "      <td>2019-02-24 17:38:41</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-21 22:25:00</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46283874465</td>\n",
       "      <td>Action Joe - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>action joe atana studio anthony sejourne</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4628...</td>\n",
       "      <td>2019-02-24 17:38:42</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-21 22:31:21</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32256187777</td>\n",
       "      <td>Ressort Rennes - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>ressort rennes atana studio anthony sejourne</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/3225...</td>\n",
       "      <td>2019-02-24 17:38:43</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-22 16:48:57</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46474676184</td>\n",
       "      <td>Colors - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>colors atana studio anthony sejourne</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4647...</td>\n",
       "      <td>2019-02-24 17:38:43</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>2019-02-22 16:50:45</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29536</th>\n",
       "      <td>32033088317</td>\n",
       "      <td>Lego Flying Tug Boat - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>lego flying tug boat tribute ian mcque brick a...</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/3203...</td>\n",
       "      <td>2019-02-03 22:02:26</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-03 11:46:53</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29537</th>\n",
       "      <td>47146974932</td>\n",
       "      <td>Le Thabor</td>\n",
       "      <td>132905622@N08</td>\n",
       "      <td>48.114193</td>\n",
       "      <td>-1.673054</td>\n",
       "      <td>rennes bretagne eglise parc thabor</td>\n",
       "      <td>https://www.flickr.com/photos/132905622@N08/47...</td>\n",
       "      <td>2019-02-24 18:35:30</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>2019-02-24 16:54:28</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>16</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29538</th>\n",
       "      <td>46243760324</td>\n",
       "      <td>FRAC Rennes - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.129942</td>\n",
       "      <td>-1.694072</td>\n",
       "      <td>frac rennes cecile bart atana studio anthony s...</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4624...</td>\n",
       "      <td>2019-02-03 11:32:10</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>2019-02-02 16:20:10</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29539</th>\n",
       "      <td>32163941887</td>\n",
       "      <td>Eternité des Horizons-5</td>\n",
       "      <td>129456011@N08</td>\n",
       "      <td>48.112331</td>\n",
       "      <td>-1.689941</td>\n",
       "      <td></td>\n",
       "      <td>https://www.flickr.com/photos/129456011@N08/32...</td>\n",
       "      <td>2019-02-15 21:06:04</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-02-13 12:50:36</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29540</th>\n",
       "      <td>45914545045</td>\n",
       "      <td>LEGO dog's bot - atana studio</td>\n",
       "      <td>27111862@N06</td>\n",
       "      <td>48.099406</td>\n",
       "      <td>-1.671262</td>\n",
       "      <td>lego brick afol moc creator atana studio antho...</td>\n",
       "      <td>https://www.flickr.com/photos/atanastudio/4591...</td>\n",
       "      <td>2019-01-21 21:25:29</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>2019-01-19 12:51:53</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29541 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id_photo                                title id_photographer  \\\n",
       "0      47146974932                            Le Thabor   132905622@N08   \n",
       "1      46283874935        Ressort Rennes - atana studio    27111862@N06   \n",
       "2      46283874465            Action Joe - atana studio    27111862@N06   \n",
       "3      32256187777        Ressort Rennes - atana studio    27111862@N06   \n",
       "4      46474676184                Colors - atana studio    27111862@N06   \n",
       "...            ...                                  ...             ...   \n",
       "29536  32033088317  Lego Flying Tug Boat - atana studio    27111862@N06   \n",
       "29537  47146974932                            Le Thabor   132905622@N08   \n",
       "29538  46243760324           FRAC Rennes - atana studio    27111862@N06   \n",
       "29539  32163941887              Eternité des Horizons-5   129456011@N08   \n",
       "29540  45914545045        LEGO dog's bot - atana studio    27111862@N06   \n",
       "\n",
       "             lat      long                                               tags  \\\n",
       "0      48.114193 -1.673054                 rennes bretagne eglise parc thabor   \n",
       "1      48.099406 -1.671262       ressort rennes atana studio anthony sejourne   \n",
       "2      48.099406 -1.671262           action joe atana studio anthony sejourne   \n",
       "3      48.099406 -1.671262       ressort rennes atana studio anthony sejourne   \n",
       "4      48.099406 -1.671262               colors atana studio anthony sejourne   \n",
       "...          ...       ...                                                ...   \n",
       "29536  48.099406 -1.671262  lego flying tug boat tribute ian mcque brick a...   \n",
       "29537  48.114193 -1.673054                 rennes bretagne eglise parc thabor   \n",
       "29538  48.129942 -1.694072  frac rennes cecile bart atana studio anthony s...   \n",
       "29539  48.112331 -1.689941                                                      \n",
       "29540  48.099406 -1.671262  lego brick afol moc creator atana studio antho...   \n",
       "\n",
       "                                                     url        date_uploaded  \\\n",
       "0      https://www.flickr.com/photos/132905622@N08/47...  2019-02-24 18:35:30   \n",
       "1      https://www.flickr.com/photos/atanastudio/4628...  2019-02-24 17:38:41   \n",
       "2      https://www.flickr.com/photos/atanastudio/4628...  2019-02-24 17:38:42   \n",
       "3      https://www.flickr.com/photos/atanastudio/3225...  2019-02-24 17:38:43   \n",
       "4      https://www.flickr.com/photos/atanastudio/4647...  2019-02-24 17:38:43   \n",
       "...                                                  ...                  ...   \n",
       "29536  https://www.flickr.com/photos/atanastudio/3203...  2019-02-03 22:02:26   \n",
       "29537  https://www.flickr.com/photos/132905622@N08/47...  2019-02-24 18:35:30   \n",
       "29538  https://www.flickr.com/photos/atanastudio/4624...  2019-02-03 11:32:10   \n",
       "29539  https://www.flickr.com/photos/129456011@N08/32...  2019-02-15 21:06:04   \n",
       "29540  https://www.flickr.com/photos/atanastudio/4591...  2019-01-21 21:25:29   \n",
       "\n",
       "       date_uploaded_year  date_uploaded_month  date_uploaded_day  \\\n",
       "0                    2019                    2                 24   \n",
       "1                    2019                    2                 24   \n",
       "2                    2019                    2                 24   \n",
       "3                    2019                    2                 24   \n",
       "4                    2019                    2                 24   \n",
       "...                   ...                  ...                ...   \n",
       "29536                2019                    2                  3   \n",
       "29537                2019                    2                 24   \n",
       "29538                2019                    2                  3   \n",
       "29539                2019                    2                 15   \n",
       "29540                2019                    1                 21   \n",
       "\n",
       "       date_uploaded_hour  date_uploaded_minutes           date_taken  \\\n",
       "0                      18                     35  2019-02-24 16:54:28   \n",
       "1                      17                     38  2019-02-21 22:25:00   \n",
       "2                      17                     38  2019-02-21 22:31:21   \n",
       "3                      17                     38  2019-02-22 16:48:57   \n",
       "4                      17                     38  2019-02-22 16:50:45   \n",
       "...                   ...                    ...                  ...   \n",
       "29536                  22                      2  2019-02-03 11:46:53   \n",
       "29537                  18                     35  2019-02-24 16:54:28   \n",
       "29538                  11                     32  2019-02-02 16:20:10   \n",
       "29539                  21                      6  2019-02-13 12:50:36   \n",
       "29540                  21                     25  2019-01-19 12:51:53   \n",
       "\n",
       "       date_taken_year  date_taken_month  date_taken_day  date_taken_hour  \\\n",
       "0                 2019                 2              24               16   \n",
       "1                 2019                 2              21               22   \n",
       "2                 2019                 2              21               22   \n",
       "3                 2019                 2              22               16   \n",
       "4                 2019                 2              22               16   \n",
       "...                ...               ...             ...              ...   \n",
       "29536             2019                 2               3               11   \n",
       "29537             2019                 2              24               16   \n",
       "29538             2019                 2               2               16   \n",
       "29539             2019                 2              13               12   \n",
       "29540             2019                 1              19               12   \n",
       "\n",
       "       date_taken_minutes  \n",
       "0                      54  \n",
       "1                      25  \n",
       "2                      31  \n",
       "3                      48  \n",
       "4                      50  \n",
       "...                   ...  \n",
       "29536                  46  \n",
       "29537                  54  \n",
       "29538                  20  \n",
       "29539                  50  \n",
       "29540                  51  \n",
       "\n",
       "[29541 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Traitement des tags\n",
    "O00OOOOOO0OO0O0OO ={'à':'a','ã':'a','á':'a','â':'a','é':'e','è':'e','ê':'e','ë':'e','î':'i','ï':'i','ô':'o','ö':'o','ù':'u','ü':'u','û':'u',}\n",
    "OOOOOO0OO00O0OO00 =re .compile (r'^[\\w-]+$')\n",
    "def OO0OOO0O00OOO0OOO (O00O0O0O00OOOO00O ,O0O0O00OO0OOO00OO ):\n",
    "    O00O0O0O00OOOO00O =O00O0O0O00OOOO00O .lower ()\n",
    "    O0O0O00O00O00O0OO =[]\n",
    "    for O0OO0OOO0OOOO0OO0 in O00O0O0O00OOOO00O .split ():\n",
    "        OO000O0000OOO0O0O =[]\n",
    "        for O0OO0OOO00O0OO0O0 in O0OO0OOO0OOOO0OO0 :\n",
    "            OO000O0000OOO0O0O .append (O00OOOOOO0OO0O0OO [O0OO0OOO00O0OO0O0 ]if O0OO0OOO00O0OO0O0 in O00OOOOOO0OO0O0OO else O0OO0OOO00O0OO0O0 )\n",
    "        O0OO0OOO0OOOO0OO0 =''.join (OO000O0000OOO0O0O )\n",
    "        if O0OO0OOO0OOOO0OO0 in O0O0O00OO0OOO00OO :\n",
    "            continue \n",
    "        if O0OO0OOO0OOOO0OO0 .startswith (\"img_\")or O0OO0OOO0OOOO0OO0 .startswith (\"dsc_\"):\n",
    "            continue \n",
    "        if OOOOOO0OO00O0OO00 .match (O0OO0OOO0OOOO0OO0 )is None :\n",
    "            continue \n",
    "        O0O0O00O00O00O0OO .append (O0OO0OOO0OOOO0OO0 )\n",
    "    return ' '.join (O0O0O00O00O00O0OO )\n",
    "def magic (O0O0O0O000O0OO000 ,OOO0000O0OO0O0OOO ):\n",
    "    O0O0O0O000O0OO000 [\"tags\"]=O0O0O0O000O0OO000 [\"tags\"].fillna (\"\")\n",
    "    OOOO000OOOOOO00OO =[]\n",
    "    for _O0OO00O00OOOO00O0 ,O000O0O00000O00O0 in O0O0O0O000O0OO000 .iterrows ():\n",
    "        OOOO000OOOOOO00OO .append (OO0OOO0O00OOO0OOO (O000O0O00000O00O0 [\"tags\"],OOO0000O0OO0O0OOO ))\n",
    "    O0O0O0O000O0OO000 [\"tags\"]=OOOO000OOOOOO00OO\n",
    "# En supposant que la version actuelle du dataframe est sotckée dans une variable \"photos\":\n",
    "magic(photos, stopwordslist)\n",
    "photos\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des tags associés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple d'utilisation de l'algorithme Apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous, nous vous donnons un exemple d'utilisation de l'algorithme Apriori vu en cours pour extraire les itemsets fréquents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
       " ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
       " ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
       " ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
       " ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intialisation du jeu de données sous la forme d'un tableau de tableaux\n",
    "dataset = [['Milk', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Dill', 'Onion', 'Nutmeg', 'Kidney Beans', 'Eggs', 'Yogurt'],\n",
    "           ['Milk', 'Apple', 'Kidney Beans', 'Eggs'],\n",
    "           ['Milk', 'Unicorn', 'Corn', 'Kidney Beans', 'Yogurt'],\n",
    "           ['Corn', 'Onion', 'Onion', 'Kidney Beans', 'Ice cream', 'Eggs']]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apple</th>\n",
       "      <th>Corn</th>\n",
       "      <th>Dill</th>\n",
       "      <th>Eggs</th>\n",
       "      <th>Ice cream</th>\n",
       "      <th>Kidney Beans</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Nutmeg</th>\n",
       "      <th>Onion</th>\n",
       "      <th>Unicorn</th>\n",
       "      <th>Yogurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Apple   Corn   Dill   Eggs  Ice cream  Kidney Beans   Milk  Nutmeg  Onion  \\\n",
       "0  False  False  False   True      False          True   True    True   True   \n",
       "1  False  False   True   True      False          True  False    True   True   \n",
       "2   True  False  False   True      False          True   True   False  False   \n",
       "3  False   True  False  False      False          True   True   False  False   \n",
       "4  False   True  False   True       True          True  False   False   True   \n",
       "\n",
       "   Unicorn  Yogurt  \n",
       "0    False    True  \n",
       "1    False    True  \n",
       "2    False   False  \n",
       "3     True    True  \n",
       "4    False   False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation des données en dataframe\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "t_encoder = TransactionEncoder()\n",
    "t_array = t_encoder.fit(dataset).transform(dataset)\n",
    "df = pd.DataFrame(t_array, columns = t_encoder.columns_)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion, Kidney Beans)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Yogurt)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Onion, Kidney Beans)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                     itemsets\n",
       "0       0.8                       (Eggs)\n",
       "1       1.0               (Kidney Beans)\n",
       "2       0.6                       (Milk)\n",
       "3       0.6                      (Onion)\n",
       "4       0.6                     (Yogurt)\n",
       "5       0.8         (Eggs, Kidney Beans)\n",
       "6       0.6                (Eggs, Onion)\n",
       "7       0.6         (Milk, Kidney Beans)\n",
       "8       0.6        (Onion, Kidney Beans)\n",
       "9       0.6       (Kidney Beans, Yogurt)\n",
       "10      0.6  (Eggs, Onion, Kidney Beans)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Application d'Apriori avec minsup=60% sur le dataframe\n",
    "frequent_itemsets = apriori(df, min_support = 0.6, use_colnames = True)\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>(Kidney Beans)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Yogurt)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.8</td>\n",
       "      <td>(Eggs, Kidney Beans)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Onion)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Milk, Kidney Beans)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Onion, Kidney Beans)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Kidney Beans, Yogurt)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.6</td>\n",
       "      <td>(Eggs, Onion, Kidney Beans)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    support                     itemsets  length\n",
       "0       0.8                       (Eggs)       1\n",
       "1       1.0               (Kidney Beans)       1\n",
       "2       0.6                       (Milk)       1\n",
       "3       0.6                      (Onion)       1\n",
       "4       0.6                     (Yogurt)       1\n",
       "5       0.8         (Eggs, Kidney Beans)       2\n",
       "6       0.6                (Eggs, Onion)       2\n",
       "7       0.6         (Milk, Kidney Beans)       2\n",
       "8       0.6        (Onion, Kidney Beans)       2\n",
       "9       0.6       (Kidney Beans, Yogurt)       2\n",
       "10      0.6  (Eggs, Onion, Kidney Beans)       3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comptage du nombre d'items par itemset\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des mots fréquents par cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, on va extraire les itemsets fréquents des tags de chaque cluster et choisir l'itemset le plus fréquent et le plus long comme étiquette de ce cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cluster'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d0c675476489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Construction d'une table de hachage qui associe à chaque numéro de cluster une étiquette \"no label\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphotos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcluster_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"no label\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcluster_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cluster'"
     ]
    }
   ],
   "source": [
    "# Construction d'une table de hachage qui associe à chaque numéro de cluster une étiquette \"no label\"\n",
    "cluster_labels = {}\n",
    "for cluster in photos[\"cluster\"].unique():\n",
    "    cluster_labels[cluster] = \"no label\"\n",
    "cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Pour chaque cluster extraire les itemsets fréquents afin de déterminer une étiquette par cluster.*\n",
    "</font>  \n",
    "Indication : Pour chaque cluster :   \n",
    "1. calculer les motifs fréquents de longueur (nombre d'items) au moins 2,  \n",
    "1. les trier par support puis par longueur,  \n",
    "1. ne garder que le plus fréquent, \n",
    "1. associer ce motif comme étiquette au cluster dans la table de hachage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_cluster(cluster_nb):\n",
    "    pass\n",
    "\n",
    "for cluster_nb in cluster_labels:\n",
    "    identify_cluster(cluster_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=orange>**Question** : *Associer le cluster et son étiquette dans l'affichage avec la carte.*\n",
    "</font>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
